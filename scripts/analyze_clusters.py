import pandas as pd
import argparse
import os
from typing import Dict

def parse_args() -> argparse.Namespace:
    """Parse command-line arguments for the script."""
    parser = argparse.ArgumentParser(description="Analyze functional annotations of protein clusters.")
    parser.add_argument(
        "--cluster_results", 
        type=str, 
        required=True, 
        help="Path to the clustering_results.csv file generated by the previous script."
    )
    parser.add_argument(
        "--interpro_annotations", 
        type=str, 
        required=True, 
        help="Path to the InterPro matches .tsv file downloaded from MGnify."
    )
    parser.add_argument(
        "--output_file", 
        type=str, 
        default="functional_analysis_summary.txt", 
        help="Path to save the summary report."
    )
    parser.add_argument(
        "--top_n", 
        type=int, 
        default=10, 
        help="Number of top functions to show for each cluster."
    )
    return parser.parse_args()

def analyze_clusters(clusters_df: pd.DataFrame, annotations_df: pd.DataFrame, top_n: int) -> Dict[int, pd.Series]:
    """
    Merges cluster and annotation data and summarizes the top functions in each cluster.

    Args:
        clusters_df (pd.DataFrame): DataFrame with protein headers and cluster labels.
        annotations_df (pd.DataFrame): DataFrame with protein IDs and InterPro descriptions.
        top_n (int): The number of most frequent functions to report per cluster.

    Returns:
        Dict[int, pd.Series]: A dictionary mapping cluster ID to a Series of its top N functions and their counts.
    """
    # Merge the two dataframes on the protein identifier.
    # We use a 'left' merge to keep all proteins from our clustering analysis.
    merged_df = pd.merge(clusters_df, annotations_df, left_on='header', right_on='protein_id', how='left')

    # Drop rows where there was no functional annotation
    merged_df.dropna(subset=['signature_description'], inplace=True)

    summary = {}
    
    # Use the superior HDBSCAN results for analysis
    cluster_ids = sorted(merged_df['HDBSCAN_label'].unique())

    for cluster_id in cluster_ids:
        # Skip the noise cluster (-1)
        if cluster_id == -1:
            continue
        
        # Filter the dataframe for the current cluster
        cluster_data = merged_df[merged_df['HDBSCAN_label'] == cluster_id]
        
        # Count the occurrences of each function description
        function_counts = cluster_data['signature_description'].value_counts()
        
        # Store the top N functions in our summary dictionary
        summary[cluster_id] = function_counts.head(top_n)
        
    return summary

def main():
    """Main execution function."""
    args = parse_args()

    print(f"Loading cluster results from: {args.cluster_results}")
    clusters_df = pd.read_csv(args.cluster_results)

    # Pre-process the header to extract the clean protein ID before merging.
    # This splits the header by the first space and keeps the ID part.
    print("Cleaning protein IDs from cluster results...")
    clusters_df['header'] = clusters_df['header'].str.split(' ').str[0]

    print(f"Loading InterPro annotations from: {args.interpro_annotations}")
    
    # --- UPDATED TSV LOADING LOGIC ---
    # Read the TSV file, telling pandas the first row is a header.
    # We specifically use the columns we need to make the script more robust.
    try:
        annotations_df = pd.read_csv(
            args.interpro_annotations, 
            sep='\t', 
            header=0, # Treat the first row as the header
            usecols=['protein_accession', 'signature_description'] # Only load these specific columns
        )
        # The 'analyze_clusters' function expects the ID column to be 'protein_id'.
        # We rename the column after loading for compatibility.
        annotations_df.rename(columns={'protein_accession': 'protein_id'}, inplace=True)

    except ValueError as e:
        print(f"Error reading TSV file: {e}")
        print("Please ensure your TSV file has a header row with at least 'protein_accession' and 'signature_description' columns.")
        return
    except Exception as e:
        print(f"An unexpected error occurred while reading the TSV file: {e}")
        return


    print("Analyzing cluster functions...")
    analysis_summary = analyze_clusters(clusters_df, annotations_df, args.top_n)

    print(f"Saving summary to: {args.output_file}")
    with open(args.output_file, 'w') as f:
        f.write("Functional Analysis of HDBSCAN Protein Clusters\n")
        f.write("=" * 50 + "\n\n")

        for cluster_id, functions in analysis_summary.items():
            # Get the total number of proteins in this cluster from the original df
            total_proteins_in_cluster = len(clusters_df[clusters_df['HDBSCAN_label'] == cluster_id])
            
            f.write(f"--- Cluster {cluster_id} (Total Proteins: {total_proteins_in_cluster}) ---\n")
            if functions.empty:
                f.write("No functional annotations found for this cluster.\n")
            else:
                f.write(f"Top {args.top_n} most frequent functions:\n")
                f.write(functions.to_string())
                f.write("\n")
            f.write("\n" + "-" * 25 + "\n\n")
    
    print("Analysis complete.")

if __name__ == '__main__':
    main()

